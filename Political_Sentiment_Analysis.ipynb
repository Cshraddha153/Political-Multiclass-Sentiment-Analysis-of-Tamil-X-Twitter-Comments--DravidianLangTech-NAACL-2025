{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y4Z2G8fdIw_",
        "outputId": "54d410a1-4b52-443a-e305-1ac0ca82311c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw2ID0U9dpHU",
        "outputId": "60377ed1-975e-4d29-b1ef-4373f9f59dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.10/dist-packages (0.41.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.6.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.8.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.2.2)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (24.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\n",
            "Requirement already satisfied: syntok>1.3.3 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.4.4)\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.47.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.2.0)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.89.0)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-bert>=0.86.0->ktrain) (1.26.4)\n",
            "Requirement already satisfied: keras-transformer==0.40.0 in /usr/local/lib/python3.10/dist-packages (from keras-bert>=0.86.0->ktrain) (0.40.0)\n",
            "Requirement already satisfied: keras-pos-embd==0.13.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.13.0)\n",
            "Requirement already satisfied: keras-multi-head==0.29.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.29.0)\n",
            "Requirement already satisfied: keras-layer-normalization==0.16.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.16.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
            "Requirement already satisfied: keras-embed-sim==0.10.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.10/dist-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.51.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2024.2)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2024.11.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2024.12.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.27.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers->ktrain) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers->ktrain) (4.12.2)\n",
            "Requirement already satisfied: tf_keras in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tf_keras) (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf_keras) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf_keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf_keras) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf_keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf_keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ktrain\n",
        "!pip install tf_keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95UTaotVc_dg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
        "import ktrain\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJjUpmjVc_de"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Political Multiclass Sentiment Analysis of Tamil/PS_train.csv')\n",
        "val_df =pd.read_csv('/content/drive/MyDrive/Political Multiclass Sentiment Analysis of Tamil/PS_dev.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Political Multiclass Sentiment Analysis of Tamil/PS_test_without_lables.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_fAd-W7VrYR"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "import random\n",
        "\n",
        "none_above_df = train_df[train_df['labels'] == 'None of the above']\n",
        "none_above_resampled = none_above_df.sample(n=300, replace=True, random_state=42)\n",
        "train_df = pd.concat([train_df, none_above_resampled], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcuCWrDvVGdp"
      },
      "outputs": [],
      "source": [
        "train_text = train_df['content']\n",
        "val_text = val_df['content']\n",
        "test_text = test_df['content']\n",
        "\n",
        "train_labels = train_df['labels']\n",
        "val_labels = val_df['labels']\n",
        "# test_labels = test_df['labels']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_tamil_text(text):\n",
        "    # Remove hashtags, question marks, commas, and periods\n",
        "    text = re.sub(r\"[#?,.]\", \"\", text)\n",
        "    text = text.lower()\n",
        "    # Remove emojis (all unicode symbols in emoji range)\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese characters\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r\"\", text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    # words = text.split()\n",
        "\n",
        "    # Filter out stop words\n",
        "    # text = [word for word in words if word not in tamil_stopwords]\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "# tamil_text = \"‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç #‡ÆÆ‡Øä‡Æ¥‡Æø ‡ÆÆ‡Æø‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç ‡Æö‡Æø‡Æ±‡Æ®‡Øç‡Æ§‡Æ§‡Ææ? üòä, ‡ÆÜ‡Æ©‡Ææ‡Æ≤‡Øç ‡Æá‡Æ§‡ØÅ ‡Æ™‡Æü‡Æø‡Æï‡Øç‡Æï ‡Æö‡ØÅ‡Æµ‡Ææ‡Æ∞‡Æ∏‡Øç‡ÆØ‡ÆÆ‡Ææ‡Æï ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ.\"\n",
        "# preprocessed_text = preprocess_tamil_text(tamil_text)\n",
        "# print(preprocessed_text)\n"
      ],
      "metadata": {
        "id": "rVMIHoVVHEmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying preprocessing to train, val, and test data\n",
        "train_text = train_df['content'].apply(preprocess_tamil_text)\n",
        "val_text = val_df['content'].apply(preprocess_tamil_text)\n",
        "test_text = test_df['content'].apply(preprocess_tamil_text)"
      ],
      "metadata": {
        "id": "Vrh-HXo0XK0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display preprocessed text\n",
        "print(\"Train Text:\\n\", train_text.head())\n",
        "print(\"Validation Text:\\n\", val_text.head())\n",
        "print(\"Test Text:\\n\", test_text.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Aq6tzBlX1wa",
        "outputId": "d1015cf6-25b0-43c2-eba0-2dc431b92efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Text:\n",
            " 0    ‡Æ§‡ØÜ‡Æ©‡Øç‡Æï‡Ææ‡Æö‡Æø ‡Æ§‡Øä‡Æï‡ØÅ‡Æ§‡Æø ‡Æ™‡ØÅ‡Æ§‡Æø‡ÆØ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Æï‡ÆÆ‡Øç ‡Æï‡Æü‡Øç‡Æö‡Æø ‡Æµ‡Øá‡Æü‡Øç‡Æ™‡Ææ‡Æ≥‡Æ∞‡Øç ...\n",
            "1    ‡ÆÖ‡Æ£‡Øç‡Æ£‡Æ©‡Øç ‡Æá‡Æ§‡Æ©‡Øà ‡Æö‡ØÇ‡Æö‡Æï‡ÆÆ‡Ææ‡Æï 11 ‡ÆÆ‡Ææ‡Æ§‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÆ‡ØÅ‡Æ©‡Øç‡Æ™‡Øá ‡Æ™‡Øá‡Æü‡Øç‡Æü‡Æø‡ÆØ...\n",
            "2    ‡Æí‡Æ∞‡ØÅ ‡Æµ‡Æ∞‡ØÅ‡Æü‡ÆÆ‡Øç ‡ÆÜ‡Æï‡Æø ‡Æµ‡Æø‡Æü‡Øç‡Æü‡Æ§‡ØÅ ‡Æá‡Æ®‡Øç‡Æ§ ‡Æ§‡ØÅ‡ÆØ‡Æ∞‡ÆÆ‡Øç ‡Æ®‡Øá‡Æ∞‡Øç‡Æ®‡Øç‡Æ§‡ØÅ ‡Æá‡Æ©...\n",
            "3    ‡Æé‡Æü‡Æ™‡Øç‡Æ™‡Ææ‡Æü‡Æø‡ÆØ‡Øà ‡Æï‡Æ£‡Øç‡Æü‡ØÅ‡Æï‡Øä‡Æ≥‡Øç‡Æ≥‡Ææ‡Æ§ \"‡Æé‡Æü‡Æ™‡Øç‡Æ™‡Ææ‡Æü‡Æø\" --- ‡ÆÜ‡Æ§‡Æ∞‡Æø‡Æ™‡Øç‡Æ™...\n",
            "4    ‡Æé‡Æô‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡ÆÖ‡Æ∞‡Æö‡Æø‡ÆØ‡Æ≤‡Øç ‡ÆÖ‡Æü‡ØÅ‡Æ§‡Øç‡Æ§ ‡Æ§‡Æ≤‡Øà‡ÆÆ‡ØÅ‡Æ±‡Øà‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Ææ‡Æ©‡Æ§‡ØÅ ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≥...\n",
            "Name: content, dtype: object\n",
            "Validation Text:\n",
            " 0    ‡Æí‡Æ±‡Øç‡Æ±‡Øá ‡ÆÖ‡Æ±‡Øà ‡Æ™‡Ææ‡Æú‡Æï ‡Æï‡ØÅ‡Æ≥‡Øã‡Æ∏‡Øç! ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç_‡Æö‡Æø‡Æ©‡Øç‡Æ©‡ÆÆ‡Øç_‡ÆÆ‡Øà‡Æï‡Øç ‡Æö...\n",
            "1    ‡Æµ‡Ææ‡ÆØ‡Øç‡Æ™‡Øç‡Æ™‡Æø‡Æ≤‡Øç‡Æ≤‡Øà ‡Æö‡Ææ‡Æ∞‡Øç ‡Æµ‡Ææ‡ÆØ‡Øç‡Æ™‡Øç‡Æ™‡Æø‡Æ≤‡Øç‡Æ≤‡Øà ‡Æö‡ØÄ‡ÆÆ‡Ææ‡Æ©‡Æø‡Æ©‡Øç_‡Æö‡Æø‡Æ©‡Øç‡Æ©‡ÆÆ...\n",
            "2    ‡Æí‡Æ∞‡Øá ‡Æ™‡Øã‡Æü‡ØÅ ‡Æá‡Æ∞‡Æ£‡Øç‡Æü‡Ææ‡Æï ‡Æ™‡Æø‡Æ≥‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç | ‡Æµ‡Æ∞‡Æ≤‡Ææ‡Æ±‡Øç‡Æ±‡Æø‡Æ≤‡Øç ‡Æí‡Æ∞‡ØÅ‡Æµ‡Æ©‡Øç...\n",
            "3    ‡Æá‡Æ™‡Øç‡Æ™‡Æü‡Æø‡ÆØ‡ØÜ‡Æ≤‡Øç‡Æ≤‡Ææ‡ÆÆ‡Øç ‡Æé‡Æü‡Æø‡Æü‡Øç ‡Æ™‡Æ£‡Øç‡Æ£‡Æø‡Æ§‡Ææ‡Æ©‡Øç ‡Æì‡Æü‡Øç‡Æü‡ØÅ ‡Æµ‡Ææ‡Æô‡Øç‡Æï‡Æ£‡ØÅ‡ÆÆ‡Øç...\n",
            "4    mike_voiceofpeople ntk_symbol_mike ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç_‡Æö‡Æø...\n",
            "Name: content, dtype: object\n",
            "Test Text:\n",
            " 0    ‡Æá‡Æ∏‡Øç‡Æ≤‡Ææ‡ÆÆ‡Æø‡ÆØ ‡Æö‡Æï‡Øã‡Æ§‡Æ∞‡Æ∞‡Øç‡Æï‡Æ≥‡ØÅ‡Æü‡Æ©‡Øç ‡Æ∞‡ÆÆ‡Æ≤‡Ææ‡Æ©‡Øç ‡Æï‡Øä‡Æ£‡Øç‡Æü‡Ææ‡Æü‡Æø‡ÆØ ‡ÆÖ‡Æ§‡Æø‡ÆÆ‡ØÅ‡Æï...\n",
            "1    ‡Æì‡Æ™‡Æø‡Æé‡Æ∏‡Øç - ‡Æé‡Æü‡Æ™‡Øç‡Æ™‡Ææ‡Æü‡Æø ‡Æ™‡Øã‡Æü‡Øç‡Æü‡Ææ ‡Æ™‡Øã‡Æü‡Øç‡Æü‡Æø! ‡Æ§‡Æø‡Æü‡ØÄ‡Æ∞‡ØÜ‡Æ© ‡Æ™‡Æ£‡Æø‡Æï‡Æ≥...\n",
            "2    ‡Æá‡Æ©‡Øç‡Æ±‡Øà‡ÆØ ‡Æ™‡Æ∞‡Æ™‡Øç‡Æ™‡ØÅ‡Æ∞‡Øà: ‡Æ®‡Ææ‡ÆÆ‡Øç ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Æ∞‡Øç ‡Æï‡Æü‡Øç‡Æö‡Æø ‡Æ§‡Æ≤‡Øà‡ÆÆ‡Øà ‡Æí‡Æ∞‡ØÅ‡Æô‡Øç...\n",
            "3    ‡Æá‡Æ©‡Øç‡Æ©‡ØÅ‡ÆÆ‡Øç 05 ‡Æè ‡Æ®‡Ææ‡Æ≥‡Æø‡Æ≤‡Øç ‡Æµ‡ØÜ‡Æ≤‡Øç‡Æµ‡Øã‡ÆÆ‡Øç ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Æ∞‡Ææ‡ÆØ‡Øç - ‡Æ§‡Æ≤‡Øà ‡Æ®‡Æø...\n",
            "4    ‡Æü‡Ææ‡Æ∏‡Øç‡ÆÆ‡Ææ‡Æï‡Øç‡Æ≤ ‡ÆÆ‡Æü‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç‡Æ§‡Ææ‡Æ©‡Øç ‡Æï‡Æ∞‡ØÅ‡Æ£‡Ææ‡Æ®‡Æø‡Æ§‡Æø ‡ÆÖ‡Æµ‡Æ∞‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡Æ™‡ØÜ‡ÆØ‡Æ∞...\n",
            "Name: content, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "u9cyFSQKc_df",
        "outputId": "6386b794-37d1-4aaf-8177-eb3b61f257db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "labels\n",
              "Opinionated          1361\n",
              "Sarcastic             790\n",
              "Neutral               637\n",
              "Positive              575\n",
              "None of the above     471\n",
              "Substantiated         412\n",
              "Negative              406\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Opinionated</th>\n",
              "      <td>1361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sarcastic</th>\n",
              "      <td>790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neutral</th>\n",
              "      <td>637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Positive</th>\n",
              "      <td>575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>None of the above</th>\n",
              "      <td>471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Substantiated</th>\n",
              "      <td>412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Negative</th>\n",
              "      <td>406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "train_labels.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_labels = train_labels.fillna(\"Unknown\").apply(lambda x: classes_list.index(x) if x in classes_list else -1)\n",
        "# val_labels = val_labels.fillna(\"Unknown\").apply(lambda x: classes_list.index(x) if x in classes_list else -1)\n"
      ],
      "metadata": {
        "id": "CshuAxmlUNJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRzVPLxuc_df"
      },
      "outputs": [],
      "source": [
        "classes_list = [\"Opinionated\", \"Sarcastic\", \"None of the above\", \"Neutral\", \"Positive\", \"Substantiated\", \"Negative\"]\n",
        "# Map the labels to their corresponding indices\n",
        "train_labels = train_labels.apply(lambda x: classes_list.index(x))\n",
        "val_labels = val_labels.apply(lambda x: classes_list.index(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "m30HHek3c_dg",
        "outputId": "9767b0f2-2519-4df6-ed2a-54285041da85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing train...\n",
            "language: ta\n",
            "train sequence lengths:\n",
            "\tmean : 17\n",
            "\t95percentile : 31\n",
            "\t99percentile : 40\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: ta\n",
            "test sequence lengths:\n",
            "\tmean : 17\n",
            "\t95percentile : 31\n",
            "\t99percentile : 39\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "# MODEL_NAME = 'distilbert-base-multilingual-cased'\n",
        "MODEL_NAME = 'FacebookAI/xlm-roberta-base'\n",
        "t = text.Transformer(MODEL_NAME, maxlen=30, class_names=classes_list)\n",
        "trn = t.preprocess_train(np.array(train_text), np.array(train_labels))\n",
        "val = t.preprocess_test(np.array(val_text), np.array(val_labels))\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JHFDlNkc_dh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "filepath = \"model\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDMTzB-RlI2a",
        "outputId": "3536df0f-e2f2-408b-be20-dd1d74181bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 5e-05...\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.30515, saving model to model\n",
            "146/146 - 214s - loss: 1.8265 - accuracy: 0.2934 - val_loss: 1.7324 - val_accuracy: 0.3051 - 214s/epoch - 1s/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.30515 to 0.30699, saving model to model\n",
            "146/146 - 203s - loss: 1.6783 - accuracy: 0.3637 - val_loss: 1.7264 - val_accuracy: 0.3070 - 203s/epoch - 1s/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.30699 to 0.31250, saving model to model\n",
            "146/146 - 180s - loss: 1.6060 - accuracy: 0.3850 - val_loss: 1.6866 - val_accuracy: 0.3125 - 180s/epoch - 1s/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.31250 to 0.34191, saving model to model\n",
            "146/146 - 182s - loss: 1.5599 - accuracy: 0.4033 - val_loss: 1.6685 - val_accuracy: 0.3419 - 182s/epoch - 1s/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.34191 to 0.34559, saving model to model\n",
            "146/146 - 181s - loss: 1.5372 - accuracy: 0.4095 - val_loss: 1.6396 - val_accuracy: 0.3456 - 181s/epoch - 1s/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.4964 - accuracy: 0.4233 - val_loss: 1.6768 - val_accuracy: 0.3254 - 45s/epoch - 311ms/step\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.5356 - accuracy: 0.4129 - val_loss: 1.7928 - val_accuracy: 0.2886 - 45s/epoch - 308ms/step\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.34559\n",
            "146/146 - 44s - loss: 1.8249 - accuracy: 0.3123 - val_loss: 1.8319 - val_accuracy: 0.2812 - 44s/epoch - 305ms/step\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.8522 - accuracy: 0.2971 - val_loss: 1.8542 - val_accuracy: 0.2812 - 45s/epoch - 305ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.8546 - accuracy: 0.2876 - val_loss: 1.8490 - val_accuracy: 0.2812 - 45s/epoch - 306ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.34559\n",
            "146/146 - 44s - loss: 1.8424 - accuracy: 0.2921 - val_loss: 1.8429 - val_accuracy: 0.2812 - 44s/epoch - 304ms/step\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.34559\n",
            "146/146 - 46s - loss: 1.8334 - accuracy: 0.2923 - val_loss: 1.8859 - val_accuracy: 0.1397 - 46s/epoch - 313ms/step\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.6929 - accuracy: 0.3553 - val_loss: 1.7377 - val_accuracy: 0.3015 - 45s/epoch - 306ms/step\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.7111 - accuracy: 0.3594 - val_loss: 1.7606 - val_accuracy: 0.3033 - 45s/epoch - 305ms/step\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.34559\n",
            "146/146 - 46s - loss: 1.7010 - accuracy: 0.3618 - val_loss: 1.7446 - val_accuracy: 0.3107 - 46s/epoch - 315ms/step\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.6915 - accuracy: 0.3663 - val_loss: 1.7378 - val_accuracy: 0.3033 - 45s/epoch - 306ms/step\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.6736 - accuracy: 0.3684 - val_loss: 1.7141 - val_accuracy: 0.3107 - 45s/epoch - 305ms/step\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.34559\n",
            "146/146 - 46s - loss: 1.6418 - accuracy: 0.3781 - val_loss: 1.7131 - val_accuracy: 0.3107 - 46s/epoch - 317ms/step\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.6215 - accuracy: 0.3790 - val_loss: 1.7196 - val_accuracy: 0.3125 - 45s/epoch - 307ms/step\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.34559\n",
            "146/146 - 45s - loss: 1.6024 - accuracy: 0.3837 - val_loss: 1.7337 - val_accuracy: 0.3088 - 45s/epoch - 305ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7a952f053d60>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "learner.fit_onecycle(5e-5, 20, verbose=2, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bdMw8lRc_di",
        "outputId": "1d83ac50-8bb1-4f66-a179-c02d83770bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - 4s 109ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "      Opinionated       0.29      0.98      0.45       153\n",
            "        Sarcastic       0.20      0.01      0.02       115\n",
            "None of the above       0.57      0.85      0.68        20\n",
            "          Neutral       0.00      0.00      0.00        84\n",
            "         Positive       0.00      0.00      0.00        69\n",
            "    Substantiated       0.00      0.00      0.00        52\n",
            "         Negative       0.00      0.00      0.00        51\n",
            "\n",
            "         accuracy                           0.31       544\n",
            "        macro avg       0.15      0.26      0.16       544\n",
            "     weighted avg       0.15      0.31      0.16       544\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[150,   2,   1,   0,   0,   0,   0],\n",
              "       [106,   1,   8,   0,   0,   0,   0],\n",
              "       [  3,   0,  17,   0,   0,   0,   0],\n",
              "       [ 82,   0,   2,   0,   0,   0,   0],\n",
              "       [ 67,   1,   1,   0,   0,   0,   0],\n",
              "       [ 51,   1,   0,   0,   0,   0,   0],\n",
              "       [ 50,   0,   1,   0,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "learner.validate(class_names=t.get_classes())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuhVr-mDiLDI"
      },
      "outputs": [],
      "source": [
        "test_text1 = test_df['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXzWOk4ZhIoh"
      },
      "outputs": [],
      "source": [
        "model.load_weights(filepath)\n",
        "predictor = ktrain.get_predictor(learner.model, preproc=t)\n",
        "predict = predictor.predict(test_text1.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtjyI4nMc_dj"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({\n",
        "    'Id': test_df['Id'],\n",
        "    'Labels': predict\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoLbIUJ7fSxh"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/MyDrive/Political Multiclass Sentiment Analysis of Tamil/MNLP_Tamil_run3', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAi6O8QhisUc"
      },
      "outputs": [],
      "source": [
        "# run1->32 f1 score xlm_roberta\n",
        "# run2->  25     mbert 64 2e-5  stopwords removed\n",
        "#run3  ->       xlm  32  5e-5 stopwords removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLaJTYrtc_dh",
        "outputId": "f702445a-d911-4ee0-b4f8-1ea48eb83c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/12\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.28125, saving model to xlm_roberta_multiclass_sentiment_detection\n",
            "136/136 - 137s - loss: 1.8583 - accuracy: 0.2617 - val_loss: 1.7800 - val_accuracy: 0.2812 - 137s/epoch - 1s/step\n",
            "Epoch 2/12\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.28125\n",
            "136/136 - 44s - loss: 1.7654 - accuracy: 0.3132 - val_loss: 1.7682 - val_accuracy: 0.2812 - 44s/epoch - 325ms/step\n",
            "Epoch 3/12\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.28125\n",
            "136/136 - 42s - loss: 1.7384 - accuracy: 0.3178 - val_loss: 1.7468 - val_accuracy: 0.2757 - 42s/epoch - 312ms/step\n",
            "Epoch 4/12\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.28125 to 0.33640, saving model to xlm_roberta_multiclass_sentiment_detection\n",
            "136/136 - 90s - loss: 1.6897 - accuracy: 0.3509 - val_loss: 1.6649 - val_accuracy: 0.3364 - 90s/epoch - 663ms/step\n",
            "Epoch 5/12\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.33640 to 0.37132, saving model to xlm_roberta_multiclass_sentiment_detection\n",
            "136/136 - 129s - loss: 1.6374 - accuracy: 0.3743 - val_loss: 1.6123 - val_accuracy: 0.3713 - 129s/epoch - 945ms/step\n",
            "Epoch 6/12\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.37132\n",
            "136/136 - 43s - loss: 1.5806 - accuracy: 0.3994 - val_loss: 1.6283 - val_accuracy: 0.3529 - 43s/epoch - 316ms/step\n",
            "Epoch 7/12\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.37132\n",
            "136/136 - 42s - loss: 1.5408 - accuracy: 0.4182 - val_loss: 1.6698 - val_accuracy: 0.3438 - 42s/epoch - 310ms/step\n",
            "Epoch 8/12\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.37132\n",
            "136/136 - 43s - loss: 1.4776 - accuracy: 0.4517 - val_loss: 1.6498 - val_accuracy: 0.3493 - 43s/epoch - 313ms/step\n",
            "Epoch 9/12\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.37132\n",
            "136/136 - 43s - loss: 1.3805 - accuracy: 0.5009 - val_loss: 1.7727 - val_accuracy: 0.3493 - 43s/epoch - 315ms/step\n",
            "Epoch 10/12\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.37132\n",
            "136/136 - 42s - loss: 1.2864 - accuracy: 0.5317 - val_loss: 1.8065 - val_accuracy: 0.3382 - 42s/epoch - 312ms/step\n",
            "Epoch 11/12\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.37132\n",
            "136/136 - 42s - loss: 1.1968 - accuracy: 0.5740 - val_loss: 1.9551 - val_accuracy: 0.3327 - 42s/epoch - 312ms/step\n",
            "Epoch 12/12\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.37132\n",
            "136/136 - 42s - loss: 1.1347 - accuracy: 0.5938 - val_loss: 1.9334 - val_accuracy: 0.3309 - 42s/epoch - 312ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7d334af63c70>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# learner.fit_onecycle(2e-4, 12, verbose=2, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciF5f5ExjMuz",
        "outputId": "5f133b18-db33-43b6-cea4-db2977f7b705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.28125, saving model to xlm_roberta_multiclass_sentiment_detection\n",
            "68/68 - 61s - loss: 1.8319 - accuracy: 0.2888 - val_loss: 1.7799 - val_accuracy: 0.2812 - 61s/epoch - 893ms/step\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.28125 to 0.28493, saving model to xlm_roberta_multiclass_sentiment_detection\n",
            "68/68 - 48s - loss: 1.7518 - accuracy: 0.3159 - val_loss: 1.7596 - val_accuracy: 0.2849 - 48s/epoch - 710ms/step\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.28493 to 0.29779, saving model to xlm_roberta_multiclass_sentiment_detection\n",
            "68/68 - 40s - loss: 1.7382 - accuracy: 0.3297 - val_loss: 1.7367 - val_accuracy: 0.2978 - 40s/epoch - 589ms/step\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.29779 to 0.29963, saving model to xlm_roberta_multiclass_sentiment_detection\n",
            "68/68 - 47s - loss: 1.6969 - accuracy: 0.3412 - val_loss: 1.6999 - val_accuracy: 0.2996 - 47s/epoch - 688ms/step\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.29963\n",
            "68/68 - 18s - loss: 1.6530 - accuracy: 0.3534 - val_loss: 1.7134 - val_accuracy: 0.2996 - 18s/epoch - 266ms/step\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.29963\n",
            "68/68 - 18s - loss: 1.5947 - accuracy: 0.3699 - val_loss: 1.7407 - val_accuracy: 0.2923 - 18s/epoch - 267ms/step\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.29963\n",
            "68/68 - 18s - loss: 1.4905 - accuracy: 0.4352 - val_loss: 1.7390 - val_accuracy: 0.2923 - 18s/epoch - 262ms/step\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.29963\n",
            "68/68 - 17s - loss: 1.3488 - accuracy: 0.5074 - val_loss: 1.8234 - val_accuracy: 0.2978 - 17s/epoch - 254ms/step\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.29963\n",
            "68/68 - 17s - loss: 1.2111 - accuracy: 0.5756 - val_loss: 1.8969 - val_accuracy: 0.2886 - 17s/epoch - 253ms/step\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.29963\n",
            "68/68 - 17s - loss: 1.1198 - accuracy: 0.6133 - val_loss: 1.9279 - val_accuracy: 0.2886 - 17s/epoch - 257ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7d30ac8e4490>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# learner.fit_onecycle(2e-5, 10, verbose=2, callbacks=callbacks_list)  #distilbert_mbert"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}